{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bbsoft0/Downloads/bigquery.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Workspace\\ML_Mastery\\K12_IntroToSQL.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m bigquery\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Create a \"Client\" object\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Explicitly use service account credentials by specifying the private key\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# file.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39;49mClient\u001b[39m.\u001b[39;49mfrom_service_account_json(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m/home/bbsoft0/Downloads/bigquery.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Construct a reference to the \"stackoverflow\" dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Workspace/ML_Mastery/K12_IntroToSQL.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dataset_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mdataset(\u001b[39m\"\u001b[39m\u001b[39mstackoverflow\u001b[39m\u001b[39m\"\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbigquery-public-data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\cloud\\client\\__init__.py:106\u001b[0m, in \u001b[0;36m_ClientFactoryMixin.from_service_account_json\u001b[1;34m(cls, json_credentials_path, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_service_account_json\u001b[39m(\u001b[39mcls\u001b[39m, json_credentials_path, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     86\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Factory to retrieve JSON credentials while creating client.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[39m    :type json_credentials_path: str\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m             and the credentials created by the factory.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(json_credentials_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m json_fi:\n\u001b[0;32m    107\u001b[0m         credentials_info \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_fi)\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_service_account_info(credentials_info, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bbsoft0/Downloads/bigquery.json'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "# Explicitly use service account credentials by specifying the private key\n",
    "# file.\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    '/home/bbsoft0/Downloads/bigquery.json')\n",
    "\n",
    "# Construct a reference to the \"stackoverflow\" dataset\n",
    "dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of available tables\n",
    "tables = list(client.list_tables(dataset))\n",
    "list_of_tables = [table.table_id for table in tables]\n",
    "\n",
    "# Print your answer\n",
    "print(list_of_tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"posts_answers\" table\n",
    "answers_table_ref = dataset_ref.table(\"posts_answers\")\n",
    "\n",
    "# API request - fetch the table\n",
    "answers_table = client.get_table(answers_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_answers\" table\n",
    "client.list_rows(answers_table, max_results=5).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"posts_questions\" table\n",
    "questions_table_ref = dataset_ref.table(\"posts_questions\")\n",
    "\n",
    "# API request - fetch the table\n",
    "questions_table = client.get_table(questions_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_questions\" table\n",
    "client.list_rows(questions_table, max_results=5).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "questions_query = \"\"\"\n",
    "                  SELECT id, title, owner_user_id\n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "                  WHERE tags LIKE '%bigquery%'\n",
    "                  \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "questions_query_job = client.query(questions_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "questions_results = questions_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(questions_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "answers_query = \"\"\"\n",
    "                SELECT a.id, a.body, a.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n",
    "                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                    ON q.id = a.parent_id\n",
    "                WHERE q.tags LIKE '%bigquery%'\n",
    "                \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 27 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=27*10**10)\n",
    "answers_query_job = client.query(answers_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "answers_results = answers_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(answers_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "bigquery_experts_query = \"\"\"\n",
    "                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                             ON q.id = a.parent_Id\n",
    "                         WHERE q.tags LIKE '%bigquery%'\n",
    "                         GROUP BY a.owner_user_id\n",
    "                         \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "bigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "bigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(bigquery_experts_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_finder(topic, client):\n",
    "    '''\n",
    "    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "\n",
    "    Inputs:\n",
    "        topic: A string with the topic of interest\n",
    "        client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "\n",
    "    Outputs:\n",
    "        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "    '''\n",
    "    my_query = \"\"\"\n",
    "               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                   ON q.id = a.parent_Id\n",
    "               WHERE q.tags like '%{topic}%'\n",
    "               GROUP BY a.owner_user_id\n",
    "               \"\"\"\n",
    "\n",
    "    # Set up the query (a real service would have good error handling for\n",
    "    # queries that scan too much data)\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "    my_query_job = client.query(my_query, job_config=safe_config)\n",
    "\n",
    "    # API request - run the query, and return a pandas DataFrame\n",
    "    results = my_query_job.to_dataframe()\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
